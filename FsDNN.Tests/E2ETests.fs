module KS.FsDNN.Tests.E2ETests

open KS.FsDNN
open Xunit
open System.Collections.Generic

[<Fact>]
let ``Classification - multi-class multi-label`` () =
  let n = Net.makeLayers 1 1.0 { N = 7 } [ FullyConnectedLayer {| N = 10; Activation = ReLU |}
                                           FullyConnectedLayer {| N = 3; Activation = Linear |} ] (BCEWithLogitsLossLayer {| Classes = 3 |})

  // X, y = sklearn.datasets.make_multilabel_classification(n_samples=50, n_features=7, n_classes=3, n_labels=2, random_state=1); StandardScaler().fit(X).transform(X)
  let X = [[-0.00978279;  0.4793566 ; -0.98806157;  0.4793566;   0.4793566  ;-0.00978279;
            -0.00978279; -0.49892218; -0.00978279; -0.49892218;  0.4793566;   0.968496;
            -0.00978279;  0.968496  ;  1.45763539; -0.98806157; -1.47720097;  0.4793566;
             1.45763539; -0.49892218;  0.968496  ;  1.94677478;  0.4793566  ;-1.47720097;
            -0.00978279; -0.98806157; -0.00978279;  2.43591417; -1.47720097 ;-0.49892218;
            -0.00978279; -0.98806157; -0.98806157; -0.98806157; -0.98806157 ; 1.45763539;
            -1.96634036; -0.98806157;  1.45763539; -0.49892218; -0.49892218 ;-0.00978279;
            -0.00978279;  2.43591417; -0.49892218; -0.49892218;  0.4793566  ;-0.98806157;
            -0.00978279;  0.4793566 ;]
           [-0.44136906; -0.06732748; -1.18945222; -0.06732748;  2.92500514 ; 0.30671409;
            -0.06732748;  0.30671409;  2.17692198;  1.05479725; -1.56349379 ;-0.44136906;
            -0.81541064; -0.44136906; -0.44136906;  0.68075567;  0.30671409 ;-0.44136906;
            -0.06732748; -0.44136906;  0.68075567; -0.44136906;  0.30671409 ;-1.56349379;
             0.68075567; -0.06732748;  0.68075567;  0.68075567; -1.18945222 ;-1.18945222;
            -0.06732748; -0.44136906;  0.68075567;  1.42883883; -1.18945222 ;-1.18945222;
            -1.93753537;  1.42883883;  0.30671409;  0.30671409; -1.56349379 ; 0.68075567;
             0.68075567; -1.56349379; -0.06732748;  1.05479725;  0.30671409 ; 1.42883883;
            -0.81541064;  0.68075567;]
           [-0.7088121 ; -1.37750276;  1.96595054;  1.29725988; -0.04012144; -0.7088121;
            -1.37750276; -0.7088121 ; -0.7088121;  -0.37446677;  1.29725988 ; 0.29422389;
            -0.37446677; -1.71184809; -0.04012144; -1.04315743; -0.7088121  ; 1.63160521;
            -1.04315743; -0.37446677; -1.71184809; -0.7088121;  -0.04012144; -0.7088121;
            -1.04315743; -1.04315743; -0.7088121;   0.96291455;  1.29725988 ; 0.96291455;
            -0.7088121 ;  0.62856922;  0.96291455;  0.29422389;  1.63160521 ; 0.29422389;
             0.62856922; -0.37446677;  0.96291455;  1.63160521;  0.96291455 ; 0.62856922;
            -0.7088121 ; -0.37446677; -0.7088121;   0.62856922;  2.30029588 ;-0.04012144;
            -1.04315743; -0.04012144;]
           [-0.46291005;  0.88724426; -0.65578924; -1.2344268;  -0.84866842;  0.3086067;
             0.50148589;  1.08012345;  1.27300264; -1.04154761; -0.46291005 ; 1.65876101;
            -0.27003086; -1.2344268 ;  0.69436507;  0.3086067;  2.43027776 ; 2.04451939;
            -1.2344268 ; -1.04154761; -0.07715167;  0.11572751; -1.04154761;  0.3086067;
            -0.27003086; -1.04154761; -0.65578924; -0.27003086; -0.07715167 ;-0.84866842;
             1.27300264; -0.65578924; -0.84866842;  0.11572751; -0.46291005 ; 1.46588182;
            -1.04154761; -0.65578924; -0.84866842; -0.46291005;  0.11572751;  1.8516402;
             0.11572751; -1.2344268 ;  0.11572751;  2.23739857; -0.07715167 ;-0.46291005;
            -0.84866842;  1.46588182;]
           [ 0.55603826;  0.23647604;  1.83428713;  1.83428713; -0.72221061 ;-0.72221061;
            -1.36133505; -2.00045949; -0.4026484;   1.51472492; -0.4026484  ;-0.08308618;
            -0.08308618; -1.04177283; -0.4026484;   1.51472492;  0.87560048 ; 0.55603826;
            -0.72221061;  0.55603826;  0.23647604; -0.72221061;  0.55603826 ;-0.72221061;
             0.87560048; -1.36133505; -1.68089727; -0.08308618; -0.08308618; -0.4026484;
            -0.4026484 ;  0.55603826; -0.4026484;  -0.72221061;  1.1951627  ; 1.83428713;
            -0.72221061; -0.08308618;  0.87560048;  0.55603826; -0.72221061 ;-1.68089727;
            -1.04177283;  0.87560048;  1.1951627;  -0.4026484;   2.15384935 ; 0.55603826;
            -1.04177283; -0.72221061;]
           [-1.03465129; -1.39896512; -0.30602362;  1.15123172;  2.24417322 ;-0.30602362;
            -0.30602362;  1.15123172;  0.78691788;  0.78691788;  1.15123172 ;-1.03465129;
             0.42260405;  0.42260405; -1.76327896; -1.76327896;  0.42260405 ; 0.78691788;
             2.24417322; -1.39896512;  1.51554555;  0.05829021;  0.42260405 ; 0.42260405;
            -0.30602362;  0.78691788;  0.42260405; -0.67033746;  1.87985939 ;-1.39896512;
            -0.30602362; -0.30602362;  0.78691788;  0.42260405;  0.78691788 ; 0.78691788;
            -0.30602362; -0.67033746; -0.30602362; -1.39896512; -0.30602362 ;-1.39896512;
             0.42260405; -1.39896512; -1.03465129;  0.42260405;  0.05829021 ;-1.03465129;
            -0.30602362; -0.30602362;]
           [-0.67165435;  0.29475479;  0.53635707; -0.18844978;  1.26116393 ; 1.50276621;
             1.98597078; -0.67165435; -0.67165435; -0.43005207;  1.7443685  ; 0.29475479;
             0.29475479; -0.43005207; -0.43005207;  0.0531525;   0.0531525  ;-0.91325664;
            -1.87966578;  0.53635707; -0.67165435;  0.29475479; -1.39646121 ;-0.67165435;
             0.77795936;  0.29475479; -0.67165435; -0.67165435;  1.01956164;  1.7443685;
            -0.91325664;  0.53635707; -0.67165435;  0.29475479; -1.39646121 ;-0.18844978;
             1.50276621;  0.29475479;  0.77795936;  0.53635707; -0.18844978 ; 0.29475479;
            -0.91325664;  2.71077764; -0.67165435; -1.63806349; -0.18844978 ; 0.29475479;
            -0.67165435; -2.12126806;]] |> Tensor.ofListOfList

  let Y = [[1.; 0.; 1.; 1.; 1.; 1.; 1.; 0.; 0.; 1.; 1.; 1.; 1.; 0.; 1.; 1.; 0.; 0.; 0.; 1.; 0.; 0.; 0.; 1.; 1.; 1.; 0.; 0.; 1.; 1.; 0.; 1.; 1.; 1.; 1.; 1.
            1.; 1.; 1.; 1.; 1.; 0.; 0.; 1.; 1.; 0.; 1.; 1.; 0.; 0.]
           [1.; 1.; 1.; 1.; 1.; 1.; 1.; 1.; 1.; 1.; 0.; 1.; 1.; 0.; 1.; 1.; 1.; 1.; 0.; 0.; 0.; 0.; 0.; 1.; 1.; 1.; 0.; 0.; 1.; 0.; 1.; 1.; 1.; 1.; 1.; 1.
            0.; 1.; 0.; 1.; 1.; 1.; 0.; 0.; 1.; 1.; 1.; 1.; 0.; 1.]
           [0.; 0.; 1.; 1.; 1.; 0.; 0.; 0.; 0.; 1.; 0.; 0.; 1.; 0.; 0.; 0.; 0.; 0.; 0.; 0.; 0.; 0.; 0.; 1.; 0.; 1.; 0.; 0.; 1.; 0.; 0.; 1.; 1.; 1.; 1.; 0.
            0.; 1.; 0.; 0.; 1.; 0.; 0.; 0.; 0.; 0.; 0.; 1.; 0.; 0.]]

  let costs = Dictionary<int, Tensor<double>>()
  let cb = fun e _ J -> if e % 1 = 0 then costs.[e] <- J else ()
  let hp = { HyperParameters.Defaults with Epochs = 600; LearningRate = TensorR0 0.5; Regularizer = L2Regularizer 0.10; Optimizer = AdaMOptimizer AdaMOptimizerDomain.AdaMParameters.Defaults }

  let n = Trainer.trainWithGD cb n X (Y |> Tensor.ofListOfList) hp

  let Y' = X |> Net.predict n

  costs.[0] |> shouldBeEquivalentTo [ [ 2.42754482 ] ]
  costs.[10] |> shouldBeEquivalentTo [ [ 1.13169455 ] ]
  costs.[20] |> shouldBeEquivalentTo [ [ 0.10322972 ] ]

  // NOTE: These haven't been (over)fitted due to regularization.
  let Ya = Y |> array2D
  Ya.[1, 0] <- 0.99937259
  Ya.[2, 46] <- 1.0
  let Y = Ya |> toListOfList
  Y' |> shouldBeEquivalentToWithPrecision 1e-4 Y
